---
title: "R Notebook"
output: html_notebook
---


The Dogs vs. Cats dataset that you’ll use isn’t packaged with Keras. It was made available by Kaggle as part of a computer-vision competition in late 2013, back when convnets weren’t mainstream. You can download the original dataset from www.kaggle.com/c/dogs-vs-cats/data 

***
Copying images to train, validation, and test directories
***

```{r}
original_dataset_dir <- "~/datasets/catsndogs/train"

base_dir <- "~/Downloads/cats_and_dogs_small" 
dir.create(base_dir)
train_dir <- file.path(base_dir, "train") 
dir.create(train_dir)

validation_dir <- file.path(base_dir, "validation") 
dir.create(validation_dir)
test_dir <- file.path(base_dir, "test") 
dir.create(test_dir)
train_cats_dir <- file.path(train_dir, "cats") 
dir.create(train_cats_dir)

train_dogs_dir <- file.path(train_dir, "dogs") 
dir.create(train_dogs_dir)

validation_cats_dir <- file.path(validation_dir, "cats") 
dir.create(validation_cats_dir)

validation_dogs_dir <- file.path(validation_dir, "dogs") 
dir.create(validation_dogs_dir)

test_cats_dir <- file.path(test_dir, "cats")
dir.create(test_cats_dir)
test_dogs_dir <- file.path(test_dir, "dogs") 
dir.create(test_dogs_dir)

fnames <- paste0("cat.", 1:1000, ".jpg") 
file.copy(file.path(original_dataset_dir, fnames),file.path(train_cats_dir))

fnames <- paste0("cat.", 1001:1500, ".jpg") 
file.copy(file.path(original_dataset_dir, fnames),
file.path(validation_cats_dir))

fnames <- paste0("cat.", 1501:2000, ".jpg")
file.copy(file.path(original_dataset_dir, fnames),
file.path(test_cats_dir))

fnames <- paste0("dog.", 1:1000, ".jpg") 
file.copy(file.path(original_dataset_dir, fnames),
file.path(train_dogs_dir))

fnames <- paste0("dog.", 1001:1500, ".jpg") 
file.copy(file.path(original_dataset_dir, fnames),
file.path(validation_dogs_dir))

fnames <- paste0("dog.", 1501:2000, ".jpg") 
file.copy(file.path(original_dataset_dir, fnames),
file.path(test_dogs_dir))

# As a sanity check, let’s count how many pictures are in each training split (train/validation/test):

cat("total training cat images:", length(list.files(train_cats_dir)), "\n")
cat("total training dog images:", length(list.files(train_dogs_dir)), "\n")
cat("total validation cat images:", length(list.files(validation_cats_dir)), "\n")
cat("total validation dog images:", length(list.files(validation_dogs_dir)), "\n")
cat("total test cat images:", length(list.files(test_cats_dir)), "\n")
cat("total test dog images:", length(list.files(test_dogs_dir)), "\n")
```

***
Instantiating a small convnet for cats vs. dogs classification
***

```{r}
library(keras)
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
                input_shape = c(150, 150, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
   layer_flatten() %>%
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")
```

```{r}
summary(model)
```

***
Configuring the model for training
***

```{r}
model %>% compile(
loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 1e-4), metrics = c("acc")
)
```

***
Data Preprocessing

Currently, the data sits on a drive as JPEG files, so the steps for getting it into the network are roughly as follows:

1. Read the picture files.
2. Decode the JPEG content to RGB grids of pixels. 
3. Convert these into floating-point tensors.
4. Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).

It may seem a bit daunting, but thankfully Keras has utilities to take care of these steps automatically. Keras includes a number of image processing helper tools. In particular, it includes the image_data_generator() function, which can automatically turn image files on disk into batches of pre-processed tensors. This is what we will use here.

***

```{r}
train_datagen <- image_data_generator(rescale = 1/255) 
validation_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory( train_dir,
train_datagen,
target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)
validation_generator <- flow_images_from_directory( validation_dir,
validation_datagen,
target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)
```

***
Display a batch of data and labels
*** 

```{r}
batch <- generator_next(train_generator)
str(batch)
```

***
Fitting the model using a batch generator
***

```{r}
history <- model %>% fit_generator( train_generator,
steps_per_epoch = 100,
epochs = 30,
  validation_data = validation_generator,
  validation_steps = 50
)
```


***
Save the model
***

```{r}
 model %>% save_model_hdf5("cats_and_dogs_small_1.h5")
```


```{r}
plot(history)
```


***
Data augmentation
***

```{r}
datagen <- image_data_generator( 
  rescale = 1/255, 
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2, 
  horizontal_flip = TRUE, 
  fill_mode = "nearest"
)
```

```{r}
fnames <- list.files(train_cats_dir, full.names = TRUE) 
img_path <- fnames[[3]]
img <- image_load(img_path, target_size = c(150, 150)) 
img_array <- image_to_array(img)
img_array <- array_reshape(img_array, c(1, 150, 150, 3))
augmentation_generator <- flow_images_from_data( 
  img_array,
  generator = datagen,
  batch_size = 1
)

op <- par(mfrow = c(2, 2), pty = "s", mar = c(1, 0, 1, 0)) 
for (i in 1:4) {
  batch <- generator_next(augmentation_generator)
  plot(as.raster(batch[1,,,])) 
}
par(op)
```
***
Defining a new network that includes Dropout
***

```{r}
model <- keras_model_sequential() %>%
  layer_conv_2d(
    filters = 32, kernel_size = c(3, 3), 
    activation = "relu",
    input_shape = c(150, 150, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_flatten() %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("acc")
)
```

***
Training the convnet using data-augmentation generators
***

```{r}
datagen <- image_data_generator( 
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE
)

test_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory( 
  train_dir,
  datagen,
  target_size = c(150, 150),
  batch_size = 32,
  class_mode = "binary"
)

validation_generator <- flow_images_from_directory( 
  validation_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 32,
  class_mode = "binary"
)

history <- model %>% fit_generator( 
  train_generator,
  steps_per_epoch = 50,
  epochs = 100,
  validation_data = validation_generator,
  validation_steps = 50
)

```

```{r}
plot(history)
```

*** 
Saving the model
***

```{r}
model %>% save_model_hdf5("cats_and_dogs_small_2.h5")
```

***
Using a pretrained covnet
***

```{r}
library(keras)
conv_base <- application_vgg16( 
  weights = "imagenet",
  include_top = FALSE,
  input_shape = c(150, 150, 3)
)
```

```{r}
conv_base
```

***
Extracting features using the pretrained convolutional base
***

```{r}
base_dir <- "~/Downloads/cats_and_dogs_small" 
train_dir <- file.path(base_dir, "train") 
validation_dir <- file.path(base_dir, "validation")
test_dir <- file.path(base_dir, "test")
datagen <- image_data_generator(rescale = 1/255) 
batch_size <- 20

extract_features <- function(directory, sample_count) {
  features <- array(0, dim = c(sample_count, 4, 4, 512)) 
  labels <- array(0, dim = c(sample_count))
  generator <- flow_images_from_directory( 
    directory = directory,
    generator = datagen,
    target_size = c(150, 150),
    batch_size = batch_size,
    class_mode = "binary"
    )
  
  i <- 0 
  while(TRUE) {
    batch <- generator_next(generator)
    inputs_batch <- batch[[1]]
    labels_batch <- batch[[2]]
    features_batch <- conv_base %>% predict(inputs_batch)
    index_range <- ((i * batch_size)+1):((i + 1) * batch_size) 
    features[index_range,,,] <- features_batch 
    labels[index_range] <- labels_batch
    i <- i + 1
    if (i * batch_size >= sample_count)
    break 
  }
    list(
      features = features,
      labels = labels
    ) 
}
train <- extract_features(train_dir, 2000) 
validation <- extract_features(validation_dir, 1000) 
test <- extract_features(test_dir, 1000)
```

```{r}
reshape_features <- function(features) { 
  array_reshape(features, dim = c(nrow(features), 4 * 4 * 512))
}
train$features <- reshape_features(train$features) 
validation$features <- reshape_features(validation$features) 
test$features <- reshape_features(test$features)
```

***
Defining and training the densely connected classifier
***

```{r}
model <- keras_model_sequential() %>% 
  layer_dense(units = 256, 
              activation = "relu",
              input_shape = 4 * 4 * 512) %>% 
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 1, 
              activation = "sigmoid")

model %>% compile(
  optimizer = optimizer_rmsprop(lr = 2e-5),
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

history <- model %>% 
  fit(
    train$features, 
    train$labels,
    epochs = 30,
    batch_size = 20,
    validation_data = list(validation$features, validation$labels)
)
```

```{r}
plot(history)
```
***
FEATURE EXTRACTION WITH DATA AUGMENTATION
Now, let’s review the second technique we mentioned for doing feature extraction, which is much slower and more expensive, but which allows you to use data augmentation during training: extending the conv_base model and running it end to end on the inputs.
***

***
Adding a densely connected classifier on top of the convolutional base
***

```{r}
model <- keras_model_sequential() %>%
  conv_base %>%
  layer_flatten() %>%
  layer_dense(units = 256, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")
```

```{r}
model
```

```{r}
cat("This is the number of trainable weights before freezing",
      "the conv base:", length(model$trainable_weights), "\n")
freeze_weights(conv_base)
cat("This is the number of trainable weights after freezing",
      "the conv base:", length(model$trainable_weights), "\n")
```

***
With this setup, only the weights from the two dense layers that you added will be trained. That’s a total of four weight tensors: two per layer (the main weight matrix and the bias vector). Note that in order for these changes to take effect, you must first compile the model. If you ever modify weight trainability after compilation, you should then recompile the model, or these changes will be ignored.
Now you can start training your model, with the same data-augmentation configuration that you used in the previous example.


Training the model end to end with a frozen convolutional base
***

```{r}
train_datagen = image_data_generator( 
  rescale = 1/255,
  rotation_range = 40, 
  width_shift_range = 0.2, 
  height_shift_range = 0.2, 
  shear_range = 0.2,
  zoom_range = 0.2, 
  horizontal_flip = TRUE, 
  fill_mode = "nearest"
)
test_datagen <- image_data_generator(rescale = 1/255)
train_generator <- flow_images_from_directory( 
  train_dir,
  train_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)
validation_generator <- flow_images_from_directory(
  validation_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 2e-5), 
  metrics = c("accuracy")
)
```

```{r}
history <- model %>% fit_generator( 
  train_generator,
  steps_per_epoch = 100,
  epochs = 30,
  validation_data = validation_generator,
  validation_steps = 50
)
```

```{r}
plot(history)
```

